---
sidebar: sidebar 
permalink: xcp/xcp-bp-deployment-steps.html 
keywords: deployment, solution components, linux server, windows server aff a800, ha 
summary: 本节介绍用于数据传输的NetApp XCP 的部署步骤。 
---
= 部署步骤
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
本节介绍用于数据传输的NetApp XCP 的部署步骤。



== 试验台细节

下表提供了用于此部署和性能验证的测试平台的详细信息。

|===
| 解决方案组件 | 详细信息 


| XCP 版本 1.7  a| 
* 一台 Linux 服务器 - Linux（RHEL 7.9 或 RHEL 8）
* 一台 Windows 服务器 – Windows Server 2019 标准版




| 源卷的NetApp AFF存储阵列 HA 对  a| 
* AFF8080
* NetApp ONTAP 9
* NFS 协议




| 目标卷的NetApp AFF存储阵列 HA 对  a| 
* AFF A800
* ONTAP 9
* NFS 协议




| 富士通PRIMERGY RX2540服务器 | 每个配备：* 48 个 CPU * Intel Xeon * 256GB 物理内存 * 10GbE 双端口 


| 网络连接 | 10GbE 
|===


== 部署步骤 - NAS

要部署NetApp XCP 进行数据传输，首先在目标位置安装并激活 XCP 软件。您可以在 https://mysupport.netapp.com/documentation/productlibrary/index.html?productID=63064["NetApp XCP 用户指南"^]。为此，请完成以下步骤：

. 满足本节中详细说明的先决条件link:xcp-bp-netapp-xcp-overview.html#prerequisites-for-xcp["XCP 的先决条件。"]
. 从下载 XCP 软件 https://mysupport.netapp.com/site/products/all/details/netapp-xcp/downloads-tab["NetApp XCP（下载）页面"^]。
. 将下载的 XCP tar 文件复制到 XCP 服务器。
+
....
# scp Documents/OneDrive\ -\ NetApp\ Inc/XCP/software/1.6.1/NETAPP_XCP_1.6.1.tgz mailto:root@10.63.150.53:/usr/src
....
. 解压 tarfile。
+
....
[root@mastr-53 src]# tar -zxvf NETAPP_XCP_1.6.1.tgz
....
. 从下载许可证 https://xcp.netapp.com/license/xcp.xwic%20["https://xcp.netapp.com/license/xcp.xwic"^]并复制到XCP服务器。
. 激活许可证。
+
....
[root@mastr-53 linux]# ./xcp activate
[root@mastr-53 src]# cp license /opt/NetApp/xFiles/xcp/license
[root@mastr-53 src]# cd /usr/src/xcp/linux/
[root@mastr-53 linux]# ./xcp activate
....
. 找到源 NFS 端口和目标 NFS 服务器。默认端口为 2049。
+
....
[root@mastr-53 ~]# rpcinfo -p 10.63.150.213
[root@mastr-53 ~]# rpcinfo -p 10.63.150.63
....
. 检查 NFS 连接。使用 telnet 到 NFS 服务器端口检查 NFS 服务器（源和目标）。
+
....
[root@mastr-53 ~]# telnet 10.63.150.127 2049
[root@mastr-53 ~]# telnet 10.63.150.63 2049
....
. 配置目录。
+
.. 创建 NFS 卷并为 XCP 目录导出 NFS。您还可以利用操作系统 NFS 导出 XCP 目录。
+
....
A800-Node1-2::> volume create -vserver Hadoop_SVM -volume xcpcatalog -aggregate aggr_Hadoop_1 -size 50GB -state online -junction-path /xcpcatalog -policy default -unix-permissions ---rwxr-xr-x -type RW -snapshot-policy default -foreground true
A800-Node1-2::> volume mount -vserver Hadoop_SVM -volume xcpcatalog_vol -junction-path /xcpcatalog
....
.. 检查 NFS 导出。
+
....
[root@mastr-53 ~]# showmount -e 10.63.150.63 | grep xcpca
/xcpcatalog (everyone)
....
.. 更新 `xcp.ini`。
+
....
[root@mastr-53 ~]# cat /opt/NetApp/xFiles/xcp/xcp.ini
# Sample xcp config
[xcp]
catalog = 10.63.150.64:/xcpcatalog

[root@mastr-53 ~]#
....


. 使用以下方式查找源 NAS 导出 `xcp show`。寻找：
+
....
== NFS Exports ==
== Attributes of NFS Exports ==
....
+
....
[root@mastr-53 linux]# ./xcp show 10.63.150.127
== NFS Exports ==
<check here>
== Attributes of NFS Exports ==
<check here>
....
. （可选）扫描源 NAS 数据。
+
....
[root@mastr-53 linux]# ./xcp scan -newid xcpscantest4 -stats 10.63.150.127:/xcpsrc_vol
....
+
扫描源 NAS 数据有助于您了解数据布局并发现任何潜在的迁移问题。 XCP扫描操作时间与文件数量和目录深度成正比。如果您熟悉 NAS 数据，可以跳过此步骤。

. 检查由 `xcp scan`。主要搜索无法读取的文件夹和无法读取的文件。
+
....
[root@mastr-53 linux]# mount 10.63.150.64:/xcpcatalog  /xcpcatalog
base) nkarthik-mac-0:~ karthikeyannagalingam$ scp -r root@10.63.150.53:/xcpcatalog/catalog/indexes/xcpscantest4 Documents/OneDrive\ -\ NetApp\ Inc/XCP/customers/reports/
....
. （可选）更改 inode。查看 inode 的数量，并根据目录和目标卷要迁移或复制的文件数量修改该数量（如果需要）。
+
....
A800-Node1-2::> volume show -volume xcpcatalog -fields files,files-used
A800-Node1-2::> volume show -volume xcpdest -fields files,files-used
A800-Node1-2::> volume modify -volume xcpcatalog -vserver A800-Node1_vs1 -files 2000000
Volume modify successful on volume xcpcatalog of Vserver A800-Node1_vs1.

A800-Node1-2::> volume show -volume xcpcatalog -fields files,files-used
....
. 扫描目标卷。
+
....
[root@mastr-53 linux]# ./xcp scan -stats 10.63.150.63:/xcpdest
....
. 检查源和目标卷空间。
+
....
[root@mastr-53 ~]# df -h /xcpsrc_vol
[root@mastr-53 ~]# df -h /xcpdest/
....
. 使用以下方法将数据从源复制到目标 `xcp copy`并检查摘要。
+
....
[root@mastr-53 linux]# ./xcp copy -newid create_Sep091599198212 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
<command inprogress results removed>
Xcp command : xcp copy -newid create_Sep091599198212 -parallel 23 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
Stats       : 9.07M scanned, 9.07M copied, 118 linked, 9.07M indexed, 173 giants
Speed       : 1.57 TiB in (412 MiB/s), 1.50 TiB out (392 MiB/s)
Total Time  : 1h6m.
STATUS      : PASSED
[root@mastr-53 linux]#
....
+

NOTE: 默认情况下，XCP 创建七个并行进程来复制数据。这可以调整。

+

NOTE: NetApp建议源卷为只读。实时地，源卷是一个活动的、活跃的文件系统。这 `xcp copy`操作可能会失败，因为NetApp XCP 不支持由应用程序不断更改的实时源。

+
对于 Linux，XCP 需要索引 ID，因为 XCP Linux 执行编目。

. （可选）检查目标NetApp卷上的 inode。
+
....
A800-Node1-2::> volume show -volume xcpdest -fields files,files-used
vserver        volume  files    files-used
-------------- ------- -------- ----------
A800-Node1_vs1 xcpdest 21251126 15039685

A800-Node1-2::>
....
. 使用以下方式执行增量更新 `xcp sync`。
+
....
[root@mastr-53 linux]# ./xcp sync -id create_Sep091599198212
Xcp command : xcp sync -id create_Sep091599198212
Stats       : 9.07M reviewed, 9.07M checked at source, no changes, 9.07M reindexed
Speed       : 1.73 GiB in (8.40 MiB/s), 1.98 GiB out (9.59 MiB/s)
Total Time  : 3m31s.
STATUS      : PASSED
....
+
对于本文档，为了模拟实时性，将源数据中的一百万个文件重命名，然后使用 `xcp sync`。对于 Windows，XCP 需要源路径和目标路径。

. 验证数据传输。您可以使用以下方法验证源和目标是否具有相同的数据 `xcp verify`。
+
....
Xcp command : xcp verify 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
Stats       : 9.07M scanned, 9.07M indexed, 173 giants, 100% found (6.01M have data), 6.01M compared, 100% verified (data, attrs, mods)
Speed       : 3.13 TiB in (509 MiB/s), 11.1 GiB out (1.76 MiB/s)
Total Time  : 1h47m.
STATUS      : PASSED
....


XCP 文档提供了多种选项（带有示例） `scan` ， `copy` ， `sync` ， 和 `verify`运营。有关详细信息，请参阅 https://mysupport.netapp.com/documentation/productlibrary/index.html?productID=63064["NetApp XCP 用户指南"^]。


NOTE: Windows 客户应使用访问控制列表 (ACL) 复制数据。 NetApp建议使用命令 `xcp copy -acl -fallbackuser\<username> -fallbackgroup\<username or groupname> <source> <destination>`。为了获得最佳性能，考虑到源卷具有带有 ACL 的 SMB 数据以及可由 NFS 和 SMB 访问的数据，目标必须是 NTFS 卷。使用 XCP（NFS 版本），从 Linux 服务器复制数据并与 `-acl`和 `-nodata`Windows 服务器选项将 ACL 从源数据复制到目标 SMB 数据。

详细步骤请参见 https://helpcenter.netwrix.com/NA/Configure_IT_Infrastructure/Accounts/DCA_Manage_Auditing_Security_Log.html["配置“管理审计和安全日志”策略"^]。



== 部署步骤 - HDFS/MapRFS 数据迁移

在本节中，我们讨论新的 XCP 功能“Hadoop 文件系统数据传输到 NAS”，它将数据从 HDFS/MapRFS 迁移到 NFS，反之亦然。



=== 前提条件

对于 MapRFS/HDFS 功能，您必须在非 root 用户环境中执行以下步骤。通常非 root 用户是 hdfs、mapr 或有权限在 HDFS 和 MapRFS 文件系统中进行更改的用户。

. 在 CLI 或用户的 .bashrc 文件中设置 CLASSPATH、HADOOP_HOME、NHDFS_LIBJVM_PATH、LB_LIBRARY_PATH 和 NHDFS_LIBHDFS_PATH 变量以及 `xcp`命令。
+
** NHDFS_LIBHDFS_PATH 指向 libhdfs.so 文件。该文件提供 HDFS API 来交互和操作 HDFS/MapRFS 文件和文件系统，作为 Hadoop 发行版的一部分。
** NHDFS_LIBJVM_PATH 指向 libjvm.so 文件。这是JAVA虚拟机共享库在jre中的位置。
** CLASSPATH 使用（Hadoop classpath –glob）值指向所有 jar 文件。
** LD_LIBRARY_PATH 指向 Hadoop 本机库文件夹位置。
+
请参阅以下基于 Cloudera 集群的示例。

+
[listing]
----
export CLASSPATH=$(hadoop classpath --glob)
export LD_LIBRARY_PATH=/usr/java/jdk1.8.0_181-cloudera/jre/lib/amd64/server/
export HADOOP_HOME=/opt/cloudera/parcels/CDH-6.3.4-1.cdh6.3.4.p0.6751098/
#export HADOOP_HOME=/opt/cloudera/parcels/CDH/
export NHDFS_LIBJVM_PATH=/usr/java/jdk1.8.0_181-cloudera/jre/lib/amd64/server/libjvm.so
export NHDFS_LIBHDFS_PATH=$HADOOP_HOME/lib64/libhdfs.so
----
+
在此版本中，我们支持 XCP 扫描、复制和验证操作以及从 HDFS 到 NFS 的数据迁移。您可以从数据湖集群单个工作节点和多个工作节点传输数据。在1.8版本中，root用户和非root用户都可以执行数据迁移。







=== 部署步骤 - 非 root 用户将 HDFS/MaprFS 数据迁移到NetApp NFS

. 按照部署部分步骤 1-9 中提到的相同步骤进行操作。
. 在以下示例中，用户将数据从 HDFS 迁移到 NFS。
+
.. 创建文件夹和文件（使用 `hadoop fs -copyFromLocal`) 在 HDFS 中。
+
[listing]
----
[root@n138 ~]# su - tester -c 'hadoop fs -mkdir /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
[root@n138 ~]# su - tester -c 'hadoop fs -ls -d  /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
drwxr-xr-x   - tester supergroup          0 2021-11-16 16:52 /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src
[root@n138 ~]# su - tester -c "echo 'testfile hdfs' > /tmp/a_hdfs.txt"
[root@n138 ~]# su - tester -c "echo 'testfile hdfs 2' > /tmp/b_hdfs.txt"
[root@n138 ~]# ls -ltrah /tmp/*_hdfs.txt
-rw-rw-r-- 1 tester tester 14 Nov 16 17:00 /tmp/a_hdfs.txt
-rw-rw-r-- 1 tester tester 16 Nov 16 17:00 /tmp/b_hdfs.txt
[root@n138 ~]# su - tester -c 'hadoop fs -copyFromLocal /tmp/*_hdfs.txt hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
[root@n138 ~]#
----
.. 检查 HDFS 文件夹中的权限。
+
[listing]
----
[root@n138 ~]# su - tester -c 'hadoop fs -ls hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
Found 2 items
-rw-r--r--   3 tester supergroup         14 2021-11-16 17:01 hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/a_hdfs.txt
-rw-r--r--   3 tester supergroup         16 2021-11-16 17:01 hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/b_hdfs.txt
----
.. 在 NFS 中创建一个文件夹并检查权限。
+
[listing]
----
[root@n138 ~]# su - tester -c 'mkdir /xcpsrc_vol/mohankarthiknfs_dest'
[root@n138 ~]# su - tester -c 'ls -l /xcpsrc_vol/mohankarthiknfs_dest'
total 0
[root@n138 ~]# su - tester -c 'ls -d /xcpsrc_vol/mohankarthiknfs_dest'
/xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]# su - tester -c 'ls -ld /xcpsrc_vol/mohankarthiknfs_dest'
drwxrwxr-x 2 tester tester 4096 Nov 16 14:32 /xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]#
----
.. 使用 XCP 将文件从 HDFS 复制到 NFS，并检查权限。
+
[listing]
----
[root@n138 ~]# su - tester -c '/usr/src/hdfs_nightly/xcp/linux/xcp copy -chown hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/ 10.63.150.126:/xcpsrc_vol/mohankarthiknfs_dest'
XCP Nightly_dev; (c) 2021 NetApp, Inc.; Licensed to Karthikeyan Nagalingam [NetApp Inc] until Wed Feb  9 13:38:12 2022

xcp: WARNING: No index name has been specified, creating one with name: autoname_copy_2021-11-16_17.04.03.652673

Xcp command : xcp copy -chown hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/ 10.63.150.126:/xcpsrc_vol/mohankarthiknfs_dest
Stats       : 3 scanned, 2 copied, 3 indexed
Speed       : 3.44 KiB in (650/s), 80.2 KiB out (14.8 KiB/s)
Total Time  : 5s.
STATUS      : PASSED
[root@n138 ~]# su - tester -c 'ls -l /xcpsrc_vol/mohankarthiknfs_dest'
total 0
-rw-r--r-- 1 tester supergroup 14 Nov 16 17:01 a_hdfs.txt
-rw-r--r-- 1 tester supergroup 16 Nov 16 17:01 b_hdfs.txt
[root@n138 ~]# su - tester -c 'ls -ld /xcpsrc_vol/mohankarthiknfs_dest'
drwxr-xr-x 2 tester supergroup 4096 Nov 16 17:01 /xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]#
----



